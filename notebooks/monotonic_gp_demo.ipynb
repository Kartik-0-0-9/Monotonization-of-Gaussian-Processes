{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Cell 1: imports & path setup\nimport sys, os\nsys.path.append(os.path.abspath('../functions'))  # if your notebook is in notebooks/\n\nimport numpy as np\nimport GPy\nimport matplotlib.pyplot as plt\n\nfrom monotonic_gp_utils import gp_monotonic\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Cell 2: generate synthetic data\nnp.random.seed(42)\nX = np.sort(np.random.uniform(0.1, 6, 50))[:, None]\nY = np.where(X < 3, 0.0, 0.5) + 0.05 * np.random.randn(*X.shape)\n\nplt.figure(figsize=(6, 3))\nplt.plot(X, Y, 'kx')\nplt.title('Training data (step-like)')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Cell 3: base GP and monotonic GP\nkernel = GPy.kern.RBF(input_dim=1, variance=1.0, lengthscale=2.0)\nbase_model = GPy.models.GPRegression(X, Y, kernel)\n\nmono_model = gp_monotonic(base_model, X, Y,\n                          nvd=[1.0],\n                          nu=1e-8,\n                          nv=10,\n                          force=True,\n                          display=True,\n                          optimize='on',\n                          init='sample')\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Cell 4: standard GP for comparison\nstandard_gp = GPy.models.GPRegression(X, Y, kernel.copy())\nstandard_gp.Gaussian_noise.variance = 0.01\nstandard_gp.optimize(messages=True)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Cell 5: predictions, plotting and saving result\nXtest = np.linspace(0.1, 6, 200)[:, None]\nmu_mono, var_mono = mono_model.predict(Xtest, full_cov=False, include_likelihood=False)\nmu_standard, var_standard = standard_gp.predict(Xtest, full_cov=False, include_likelihood=False)\n\n# Flatten / ensure shapes\nmu_mono = mu_mono[:, 0]\nvar_mono = np.clip(var_mono.squeeze(), 1e-6, None)\nmu_standard = mu_standard[:, 0]\nvar_standard = np.clip(var_standard.squeeze(), 1e-6, None)\n\nplt.figure(figsize=(10, 6))\nplt.plot(X, Y, 'kx', label=\"Training Data (Step Function)\")\n\nplt.plot(Xtest, mu_mono, '-', label=\"Monotonic GP Mean\")\nplt.fill_between(Xtest.ravel(),\n                 mu_mono - 2 * np.sqrt(var_mono),\n                 mu_mono + 2 * np.sqrt(var_mono),\n                 alpha=0.2, label=\"Monotonic GP 95% CI\")\n\nplt.plot(Xtest, mu_standard, '--', label=\"Standard GP Mean\")\nplt.fill_between(Xtest.ravel(),\n                 mu_standard - 2 * np.sqrt(var_standard),\n                 mu_standard + 2 * np.sqrt(var_standard),\n                 alpha=0.2, label=\"Standard GP 95% CI\")\n\nplt.title(\"Monotonic GP vs. Standard GP (Step Function)\")\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\nplt.legend()\nplt.tight_layout()\n\n# ensure results dir exists (relative to notebook location)\nos.makedirs('../results', exist_ok=True)\nplt.savefig('../results/result_plot.png', dpi=200)\nplt.show()\n\nprint('Saved plot to ../results/result_plot.png')"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
